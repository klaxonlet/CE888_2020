{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project1_main_dsdm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQyLnLlHj8i3e6Z0g7hvK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klaxonlet/CE888_2020/blob/master/project1_main_dsdm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AucUgVmOm-ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "#get_ipython().magic('matplotlib inline')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jx8SrsYlXzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "!mkdir data_pollution\n",
        "!mkdir data_housing\n",
        "%cd data_pollution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pRwkrtrlt4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"klaxonlet\" \n",
        "os.environ['KAGGLE_KEY'] = \"6a538fd5e6037f2d581d4dd78fe1aeba\" \n",
        "!kaggle datasets download -d bappekim/air-pollution-in-seoul"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcuAoklml5HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/data_housing/\n",
        "os.environ['KAGGLE_USERNAME'] = \"klaxonlet\" \n",
        "os.environ['KAGGLE_KEY'] = \"6a538fd5e6037f2d581d4dd78fe1aeba\" \n",
        "!kaggle competitions download -c sberbank-russian-housing-market"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16pTpOsmERE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSPeyB_ymf4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/data_pollution/\n",
        "!unzip air-pollution-in-seoul.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk8H3YwMHAIM",
        "colab_type": "text"
      },
      "source": [
        "Checking for covariate shift in air pollution dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6TRSt-qmy7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd AirPollutionSeoul\n",
        "data_pollution = pd.read_csv('Measurement_summary.csv') # loading our Air Pollution dataset.\n",
        "data_pollution.isna().sum() # Checking for missing values in Air Pollution data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_MA0J6HqyAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_pollution_target = data_pollution['CO']  # Saving target variable for test-train split\n",
        "data_pollution = data_pollution.drop('CO',axis=1) # Dropping target variable "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoxFiwTknyvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data into test-train split\n",
        "train_pollution, test_pollution, y_train_pollution, y_test_pollution = train_test_split(data_pollution, data_pollution_target, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shXfKPhPtc00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Label encoding\n",
        "label = LabelEncoder()\n",
        "for i in train_pollution.columns:\n",
        "    if (train_pollution[i].dtype == 'object'):\n",
        "      train_pollution[i] = label.fit_transform(train_pollution[i].astype('str'))\n",
        "      train_pollution[i] = train_pollution[i].astype('object')\n",
        "\n",
        "for i in test_pollution.columns:\n",
        "    if (test_pollution[i].dtype == 'object'):\n",
        "      test_pollution[i] = label.fit_transform(test_pollution[i].astype('str'))\n",
        "      test_pollution[i] = test_pollution[i].astype('object')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg-eh3LwutnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating new variable 'origin'\n",
        "train_pollution['origin'] = 0\n",
        "test_pollution['origin'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX-DhZwoyyuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pollution.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm95ZdKZzSCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pollution.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVRsjBunxZcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating random samples from train-test data and combining them.\n",
        "sample_train_pollution = train_pollution.sample(213679, random_state=12)\n",
        "sample_test_pollution = test_pollution.sample(212000, random_state=11)  \n",
        "\n",
        "sample_combined_pollution = sample_train_pollution.append(sample_test_pollution)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wioOVvU-0eF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_y_combined_pollution = sample_combined_pollution['origin'] # saving our 'origin' target variable.\n",
        "sample_combined_pollution = sample_combined_pollution.drop('origin',axis=1) # dropping target variable from data for modelling."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRR8lNLg2tHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "68e54d3e-a1c3-4a97-b0c0-b44106d173bd"
      },
      "source": [
        "# Creating model\n",
        "model_sample_pollution = RandomForestClassifier(n_estimators = 50, max_depth = 5,min_samples_leaf = 5)\n",
        "drop_list_pollution = []\n",
        "for i in sample_combined_pollution.columns:\n",
        "  score = cross_val_score(model_sample_pollution,pd.DataFrame(sample_combined_pollution[i]),sample_y_combined_pollution,cv=2,scoring='roc_auc')\n",
        "  if (np.mean(score) > 0.8):\n",
        "    drop_list.append(i)\n",
        "  print(i,np.mean(score))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Measurement date 0.5005021416422071\n",
            "Station code 0.4986458731725534\n",
            "Address 0.4982339374933911\n",
            "Latitude 0.49864596096536484\n",
            "Longitude 0.49839290730152863\n",
            "SO2 0.4989950561257523\n",
            "NO2 0.5004065404333504\n",
            "O3 0.4998280274102176\n",
            "PM10 0.4994099843786465\n",
            "PM2.5 0.49988216917456835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d-x4BLqGy64",
        "colab_type": "text"
      },
      "source": [
        "Checking for covariate shift in our housing market dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npx8cE0oGm3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/data_housing/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdUEkFQw8o3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_housing = pd.read_csv('train.csv') # loading our housing dataset.\n",
        "test_housing = pd.read_csv('test.csv') # loading our housing dataset.\n",
        "\n",
        "train_housing.isna().sum() # Checking for missing values in housing data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kj7tXOE9UD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imputing missing values\n",
        "for i in train_housing.columns:\n",
        "    if train_housing[i].dtype == 'object':\n",
        "      train_housing[i] = train_housing[i].fillna(train_housing[i].mode().iloc[0])\n",
        "    if (train_housing[i].dtype == 'int' or train_housing[i].dtype == 'float'):\n",
        "      train_housing[i] = train_housing[i].fillna(np.mean(train_housing[i]))\n",
        "\n",
        "\n",
        "for i in test_housing.columns:\n",
        "    if test_housing[i].dtype == 'object':\n",
        "      test_housing[i] = test_housing[i].fillna(test_housing[i].mode().iloc[0])\n",
        "    if (test_housing[i].dtype == 'int' or test_housing[i].dtype == 'float'):\n",
        "      test_housing[i] = test_housing[i].fillna(np.mean(test_housing[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thkp_qdg910w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Label encoding\n",
        "label = LabelEncoder()\n",
        "for i in train_housing.columns:\n",
        "    if (train_housing[i].dtype == 'object'):\n",
        "      train_housing[i] = label.fit_transform(train_housing[i].astype('str'))\n",
        "      train_housing[i] = train_housing[i].astype('object')\n",
        "\n",
        "for i in test_housing.columns:\n",
        "    if (test_housing[i].dtype == 'object'):\n",
        "      test_housing[i] = label.fit_transform(test_housing[i].astype('str'))\n",
        "      test_housing[i] = test_housing[i].astype('object')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3D5j81-gCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating new variable 'origin'\n",
        "train_housing['origin'] = 0\n",
        "test_housing['origin'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGtSaUcD-01k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_housing.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nGOTTRe_rvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating random samples from train-test data and combining them.\n",
        "sample_train_housing = train_housing.sample(7662, random_state=12)\n",
        "sample_test_housing = test_housing.sample(7000, random_state=11)  \n",
        "\n",
        "sample_combined_housing = sample_train_housing.append(sample_test_housing)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoCa-ExoAF_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_y_combined_housing = sample_combined_housing['origin'] # saving our 'origin' target variable.\n",
        "sample_combined_housing = sample_combined_housing.drop('origin',axis=1) # dropping target variable from data for modelling."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PUG4UKcAUZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating model\n",
        "model_sample_housing = RandomForestClassifier(n_estimators = 50, max_depth = 5,min_samples_leaf = 5)\n",
        "drop_list_housing = []\n",
        "for i in sample_combined_housing.columns:\n",
        "  score = cross_val_score(model_sample_housing,pd.DataFrame(sample_combined_housing[i]),sample_y_combined_housing,cv=2,scoring='roc_auc')\n",
        "  if (np.mean(score) > 0.8):\n",
        "    drop_list_housing.append(i)\n",
        "  print(i,np.mean(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Lh1YgHBFtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of variables that have covariate shift\n",
        "print(drop_list_housing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1k28i5SHSok",
        "colab_type": "text"
      },
      "source": [
        "Methods for dealing with covariate shift in housing market data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNC5q9E6GV18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One way to deal with covariate shift is to drop variables that have shift.\n",
        "real_train_housing = train_housing.drop('origin',axis=1)\n",
        "real_test_housing = test_housing.drop('origin',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LP0d0BhLokE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestRegressor(n_estimators=200, max_depth=6,max_features=10)\n",
        "rf.fit(real_train_housing.drop('price_doc',axis=1),real_train_housing['price_doc'])\n",
        "pred = rf.predict(real_test_housing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedPadXqM8nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['price_doc']\n",
        "submission = pd.DataFrame(data=pred,columns=columns)\n",
        "submission['id'] = real_test_housing['id']\n",
        "submission = submission[['id','price_doc']]\n",
        "submission.to_csv('with_shift.csv', index=False)\n",
        "# score in kaggle = 0.40207"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJsahJKxPa_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### plotting importances\n",
        "features = train_housing.drop('price_doc',axis=1).columns.values\n",
        "importance = rf.feature_importances_\n",
        "indices = np.argsort(importance)[::-1][:20]\n",
        "\n",
        "#plot\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(range(len(indices)), importance[indices], color = 'b', align='center')\n",
        "plt.xticks(range(len(indices)), features[indices], rotation='vertical')\n",
        "plt.xlim([-1,len(indices)])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8OugzzwPOyc",
        "colab_type": "text"
      },
      "source": [
        "Now we'll drop less important variables and check if our score improves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Dk45KvQVOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# After checking features with covariate shift and their importance we'll keep ‘life_sq’ and ‘kitch_sq’\n",
        "# and drop the rest with covariate shift.\n",
        "\n",
        "noshift_train_housing = real_train_housing.drop(['id','timestamp','hospital_beds_raion','cafe_sum_500_min_price_avg','cafe_sum_500_max_price_avg','cafe_avg_price_500'], axis=1)\n",
        "noshift_test_housing = real_test_housing.drop(['id','timestamp','hospital_beds_raion','cafe_sum_500_min_price_avg','cafe_sum_500_max_price_avg','cafe_avg_price_500'], axis=1)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=6,max_features=10)\n",
        "rf.fit(noshift_train_housing.drop('price_doc',axis=1),noshift_train_housing['price_doc'])\n",
        "noshift_pred = rf.predict(noshift_test_housing)\n",
        "columns = ['price_doc']\n",
        "sub = pd.DataFrame(data=noshift_pred,columns=columns)\n",
        "sub['id'] = real_test_housing['id']\n",
        "sub = sub[['id','price_doc']]\n",
        "sub.to_csv('without_drifting.csv', index=False)\n",
        "\n",
        "# score in kaggle = 0.40068"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1GO_rNTga8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}